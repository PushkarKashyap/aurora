# ğŸŒŒ Aurora Codex
**An Advanced Conversational Assistant for Codebase Impact Analysis**

---

[![Python](https://img.shields.io/badge/Python-3.12+-blue?logo=python&logoColor=white)](https://www.python.org/)
[![Gemini](https://img.shields.io/badge/Gemini_API-Google-4285F4?logo=google)](https://ai.google.dev/)
[![Gradio](https://img.shields.io/badge/Frontend-Gradio-orange?logo=gradio)](https://gradio.app)
[![License](https://img.shields.io/badge/License-Apache_2.0-blue.svg)](LICENSE)

---

Aurora Codex is an advanced, conversational AI assistant designed to perform deep impact analysis on your codebases. It leverages the **Google Gemini API** for Retrieval-Augmented Generation (RAG) and Python's native **Abstract Syntax Tree (AST)** module for static code analysis. The entire experience is delivered through a clean and interactive **Gradio** web interface.

---

## âœ¨ Key Features

- **Conversational Code Analysis (RAG):** Ingest any codebase and start a conversation. Ask questions about functions, dependencies, and potential impacts in natural language.
- **Static Knowledge Graph Generation:** Build a detailed structural map of your Python codebase. The tool uses AST to parse `.py` files, identify entities (functions, classes) and relationships (imports, calls), and saves this as a `knowledge_graph.json`.
- **Advanced Impact Analysis:**
  - **Criticality Assessment:** Request a prioritized analysis of impacted components, classified as High, Medium, or Low, with justifications for each.
  - **Dynamic Dependency Visualization:** Generate on-the-fly dependency graphs using Mermaid.js based on your conversation to visually understand component relationships.
- **Exportable Reports:** Download your entire impact analysis conversation as a structured Markdown report for documentation or sharing.
- **Interactive UI:**
  - A clean, themeable interface powered by Gradio.
  - Collapsible sidebar to maximize chat space.
  - Separate tabs for file ingestion, chat, and visualization.

---

## ğŸš€ Steps to Run Locally

Follow these steps to get the application running.

---

### ğŸ§© Step 1: Get a Google API Key
1.  **Go to Google AI Studio:** Open your browser and navigate to [https://aistudio.google.com/app/apikey](https://aistudio.google.com/app/apikey).
2.  **Sign In:** Use your Google account to sign in.
3.  **Create API Key:** Click the **"Create API key"** button. You may be prompted to create a new Google Cloud project; this is a standard step.
4.  **Copy Your Key:** A window will appear with your new API key. Copy this key to your clipboard.

> **âš ï¸ Important:** Treat your API key like a password. Never share it publicly or commit it to a Git repository.

### ğŸ—‚ï¸ Step 2: Set Up Your Project
1.  Clone the repository from GitHub and navigate into the directory:
    ```bash
    git clone https://github.com/PushkarKashyap/aurora
    cd aurora
    ```

2.  **Configure your environment:**
    - Create a `.env` file by copying the example:
      ```bash
      # For Windows (Command Prompt)
      copy .env.example .env
      # For macOS/Linux
      # cp .env.example .env
      ```
    - Open the new `.env` file and paste your Google API key from Step 1.

---

### ğŸ§± Step 3: Install Python Dependencies
Open your terminal in the project folder (`aurora`).

Itâ€™s recommended to use a Python virtual environment:

```bash
python -m venv venv
venv\Scripts\activate  # On Windows
# source venv/Scripts/activate  # On macOS/Linux
```

Install all required dependencies:

```bash
pip install -r requirements.txt
```

---

### ğŸ’» Step 4: Run the Gradio App
Start the web interface.

```bash
python app.py
```

Your terminal will show:
- **Local URL:** `http://127.0.0.1:7860`
- **Public URL:** `https://xxxxx.gradio.live`

Open either in your browser.

---

### ğŸ” Step 5: Analyze Your Codebase
1.  **Ingest Files:** On the **"Ingest Codebase"** tab, provide the path to your local codebase and click **"Ingest Files"**. This creates a searchable index for the RAG functionality.
2.  **Build Knowledge Graph:** Click **"Build Knowledge Graph"**. This performs a static analysis of all `.py` files and creates a `knowledge_graph.json` file. You can view the result by clicking **"View Graph"**.
3.  **Chat & Analyze:** Switch to the **"Chat"** tab.
    - Ask questions about your code's functionality and dependencies.
    - Use the **"Assess Criticality"** checkbox for a deeper, prioritized analysis.
    - After a conversation, click **"Visualize Impact"** to see a dependency diagram in the **"Visualization"** tab.
    - Download your session as a report using the **"Generate Report"** button.

---

## ğŸ§  Tech Stack
- **Backend:** Python, Google Gemini API
- **Frontend:** Gradio
- **LLM:** Gemini 2.5 Flash (default)

---

## ğŸ“‚ Project Structure

```
aurora/
â”œâ”€â”€ .env                    # <-- Local environment configuration (created from example)
â”œâ”€â”€ config.yaml             # <-- Application-wide configuration (e.g., store name, ignored dirs)
â”œâ”€â”€ .env.example
â”œâ”€â”€ .gitignore
â”œâ”€â”€ app.py                  # <-- Main application entrypoint
â”œâ”€â”€ chat.py                 # <-- Core chat logic and database interactions
â”œâ”€â”€ ingest.py               # <-- File ingestion and indexing logic
â”œâ”€â”€ prompts.yaml            # <-- All LLM prompts
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â”œâ”€â”€ .git/                   # <-- Git version control directory
â”œâ”€â”€ .gradio/                # <-- Gradio-related files (e.g., certificates)
â”œâ”€â”€ data/                   # <-- Directory for data files (if any)
â”œâ”€â”€ __pycache__/            # <-- Python cache files
â””â”€â”€ venv/                   # <-- Python virtual environment
```

---

## ğŸ“ Notes
*   The file search store name (`display_name`) can be configured in `config.yaml`.
*   The ingestion process in `ingest.py` processes files sequentially. For very large codebases, this might be slow.
*   The chat history is stored in a local SQLite database, configured via `config.yaml`.

---

## ğŸ“œ License
This project is licensed under the **Apache License 2.0**. See the `LICENSE` file for details.

---

## âœ¨ Acknowledgments
- Google for the Gemini API
- Gradio for the intuitive web interface

---

> ğŸ’¡ *â€œAurora turns your codebase into a conversational partner â€” analyze, query, and explore your projects with the power of Gemini.â€*
